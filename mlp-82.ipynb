{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup\n\nStart by specifiying: \n- SageMaker role arn used to give learning and hosting access to your data. The snippet below will use the same role used by your SageMakernotebook instance, if you're using other. Otherwise, specify the full ARN of a role with the SageMakerFullAccess policy attached.\n- The S3 bucket that you want to use for training and storing model objects","metadata":{}},{"cell_type":"code","source":"!pip install sagemaker","metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:37:57.212990Z","iopub.execute_input":"2023-08-10T20:37:57.213343Z","iopub.status.idle":"2023-08-10T20:38:17.589675Z","shell.execute_reply.started":"2023-08-10T20:37:57.213316Z","shell.execute_reply":"2023-08-10T20:38:17.588032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport boto3\nimport re\nimport sagemaker \n\nrole = sagemaker.get_execute_role()\nregion = boto3.Session().region_name\n\n#S3 bucket is used for storing code and model \nbucket = sagemaker.Session().default_bucket()\n\nprefex = (\n    \"sagemaker/DEMO-breast-cancer-prediction\"  #training files uploaded into aws s3 bucket \n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-10T20:38:35.655079Z","iopub.execute_input":"2023-08-10T20:38:35.656265Z","iopub.status.idle":"2023-08-10T20:38:35.684714Z","shell.execute_reply.started":"2023-08-10T20:38:35.656217Z","shell.execute_reply":"2023-08-10T20:38:35.682411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now We import python libraries and dependancies ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport io\nimport time\nimport json\nimport sagemaker.amazon.common as smac","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data sources\n\n**Breast Cancer Wisconcin dataset:**\nAlso can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29","metadata":{}},{"cell_type":"code","source":"s3 = boto3.client(\"s3\")\n\nfilename = \"data.csv\"\ns3.download_file(\"sagemaker-sample-files\", \"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\ndata = pd.read_csv(filename, header=None)\n\n#specify columns extracted \ndata.columns = [\n    \"id\",\n    \"diagnosis\",\n    \"radius_mean\",\n    \"texture_mean\",\n    \n    \n    \n    \n    \n]\n\n#save data\ndata.to_csv(\"data.csv\", sep\",\", index=False)\n\n# shape of data file\nprint(data.shape)\n\n# top few rows\ndisplay(data.head())\n\n# describe data objects\ndisplay(data.describe())\n\n# summarize categorical field diagnosis\ndisplay(data.diagnosis.value_count())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Key observation:\n- 569 observations\n- 32 columns\n- First field is 'id'\n- Second field, \"diagnosis\", ('M' = Maglignant; 'B' = Benign)\n- 30 other numeric features avialible ","metadata":{}},{"cell_type":"markdown","source":"# Create features and Labels \nSplit the data into 80%  training 10% and 10% testing. ","metadata":{}},{"cell_type":"code","source":"rand_split = np.random.rand(len(data))\ntrain_list = rand_split < 0.8\nval_test = (rand_split >= 0.8) & (rand_split < 0.9)\ntest_list = rand_split >= 0.9\n\ndata_train = data[train_list]\ndata_val = data[val_test]\ndata_test = data[test_list]\n\ntrain_y = ((data_train.iloc[:, 1] ==\"M\") + 0).to_numpy()\ntrain_X = data_train.iloc[:, 2:].to_numpy()\n\nval_y = ((data_val.iloc[:, 1] ==\"M\") + 0).to_numpy()\nval_X =  data_val.iloc[:, 2:].to_numpy()\n\ntest_y = ((data_test.iloc[:, 1] ==\"M\") + 0).to_numpy()\ntest_X = data_test.iloc[:, 2:].to_numpy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We then convert the datasets to  to the recordIO-wrapped protobuf format used by AWS SageMaker algorithm and then uploaded data to AWS S3 bucket. First train the data.","metadata":{}},{"cell_type":"code","source":"train_file = \"linear_train.data\"\n\nf = io.BytesIO()\nsmac.write_numpy_to_dense_tensor(f, train_X.astype(\"float32\"), train_y.astype(\"float32\"))\nf.seek(0)\n\nboto3.Session().resource(\"s3\").Bucket(bucket).Object(\n    os.path.join(prefix, \"train\", train_file)\n).upload_fileobj(f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Next convert and upload the validation dataset","metadata":{}},{"cell_type":"code","source":"validation_file = \"linear_validation.data\"\n\nf = io.BytesIO()\nsmac.write_numpy_to_dense_tensor(f, val_X.astype(\"float32\"), vsl_y.astype(\"float32\"))\nf.seek(0)\n\nboto3.Session().resource(\"s3\").Bucket(bucket).Object(\n    os.path.join(prefix, \"validation\", validation_file)\n).upload_fileobj(f)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the model\n- Specify linear model\n- Amazon SageMaker has a Leinear Learner which can fit multiple models in parallel (each contructed with different hyperparameters)so it returns the model which performs the best \n- The process of retuning the best model occurs automatically \n\n- Parameters that we can control include:\n\n1. loss - controls how model is penalized for mistakes in estimates, absolute loss is used (less sensitive to outliers)\n2. num_models - controls the number of models run in parallel. Algorithm chooses models with nerby parameter values in order to find a optimal solution Max = 32 was used.\n3. wd or l1 - controls regulazation. regulation prevets overfitting. WHich was left to the defualt \"auto\" value. ","metadata":{}},{"cell_type":"markdown","source":"# Specify container images used by SageMaker's linear learner for hosting and training","metadata":{}},{"cell_type":"code","source":"from sagemaker import image_uris\ncontainer = image_uris.retrieve(region=boto3.Session()region_name, framework=\"Linear-learner\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"linear_job = \"DEMO-linear\" + time.strtime(\"%Y-%m-%d-%H-%M-%S\", timegmtime())\n\nprint(\"Job is called:\", linear_job)\n\nlinear_training_params = {\n    \"RoleArn\": role,\n    \"TrainingJobName\": linear_job,\n    \"AlgorithmSpecification\": {\"TrainingImage\": container, \"TrainingInputMode\": \"File\"},\n    \"ResourceConfig\": {\"InstanceCount\" 1, \"InstanceType\": \"ml.c4.2xlarge\", \"VolumeSizeInGB\": 10},\n    \"inputDataCOnfig\": [\n        {\n            \"ChannelName\": 'train,\n            \"DataSource\": {\n                \"S3DataSource\": {\n                    \"S3DataType\"\n                    \"S3Uri\":\"s3://{}/{}/train/\".format(bucket, prefix),\n                    \"S3DataDistributionType\": \"ShardedByS3Key\",\n                }\n            },\n            \"CompressionType\": \"None\",\n            \"RecordWrapperType\" \"None\",\n        },\n        {\n            ","metadata":{},"execution_count":null,"outputs":[]}]}