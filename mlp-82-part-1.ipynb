{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Sagemaker Tutorial Series","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Data Source - https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification?resource=download","metadata":{}},{"cell_type":"markdown","source":"### Let's divide the workload\n1. Initialize Boto3 SDK and create S3 bucket. \n2. Upload data in Sagemaker Local Storage. \n3. Data Exploration and Understanding.\n4. Split the data into Train/Test CSV File. \n5. Upload data into the S3 Bucket.\n6. Create Training Script\n7. Train script in-side Sagemaker container. \n8. Store Model Artifacts(model.tar.gz) into the S3 Bucket. \n9. Deploy Sagemaker Endpoint(API) for trained model, and test it. ","metadata":{}},{"cell_type":"code","source":"import sklearn # Check Sklearn version\nsklearn.__version__","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Initialize Boto3 SDK and create S3 bucket. ","metadata":{"tags":[]}},{"cell_type":"code","source":"import numpy as np\nfrom sagemaker import get_execution_role\nimport sagemaker\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\nimport datetime\nimport time\nimport tarfile\nimport boto3\nimport pandas as pd\n\nsm_boto3 = boto3.client(\"sagemaker\")\nsess = sagemaker.Session()\nregion = sess.boto_session.region_name\nbucket = 'sagemaker-tutorials-mlhub' # Mention the created S3 bucket name here\nprint(\"Using bucket \" + bucket)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Data Exploration and Understanding.","metadata":{"tags":[]}},{"cell_type":"code","source":"df = pd.read_csv(\"mob_price_classification_train.csv\")","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ['Low_Risk','High_Risk'],[0,1]\ndf['price_range'].value_counts(normalize=True)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the Percentage of Values are missing\ndf.isnull().mean() * 100","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = list(df.columns)\nfeatures","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = features.pop(-1)\nlabel","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df[features]\ny = df[label]","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.head()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# {0: 'Low_Risk',1: 'High_Risk'}\ny.head()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.value_counts()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.15, random_state=0)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Split the data into Train/Test CSV File. ","metadata":{"tags":[]}},{"cell_type":"code","source":"trainX = pd.DataFrame(X_train)\ntrainX[label] = y_train\n\ntestX = pd.DataFrame(X_test)\ntestX[label] = y_test","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(trainX.shape)\nprint(testX.shape)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainX.head()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainX.isnull().sum()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testX.isnull().sum()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Upload data into the S3 Bucket.","metadata":{"tags":[]}},{"cell_type":"code","source":"trainX.to_csv(\"train-V-1.csv\",index = False)\ntestX.to_csv(\"test-V-1.csv\", index = False)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# send data to S3. SageMaker will take training data from s3\nsk_prefix = \"sagemaker/mobile_price_classification/sklearncontainer\"\ntrainpath = sess.upload_data(\n    path=\"train-V-1.csv\", bucket=bucket, key_prefix=sk_prefix\n)\n\ntestpath = sess.upload_data(\n    path=\"test-V-1.csv\", bucket=bucket, key_prefix=sk_prefix\n)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testpath","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainpath","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Create Training Script","metadata":{"tags":[]}},{"cell_type":"code","source":"%%writefile script.py\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc\nimport sklearn\nimport joblib\nimport boto3\nimport pathlib\nfrom io import StringIO \nimport argparse\nimport joblib\nimport os\nimport numpy as np\nimport pandas as pd\n\n# inference functions ---------------\n\n# def input_fn(request_body, request_content_type):\n#     print(request_body)\n#     print(request_content_type)\n#     if request_content_type == \"text/csv\":\n#         request_body = request_body.strip()\n#         try:\n#             df = pd.read_csv(StringIO(request_body), header=None)\n#             return df\n        \n#         except Exception as e:\n#             print(e)\n#     else:\n#         return \"\"\"Please use Content-Type = 'text/csv' and, send the request!!\"\"\" \n \n    \ndef model_fn(model_dir):\n    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n    return clf\n\n# def predict_fn(input_data, model):\n#     if type(input_data) != str:\n#         prediction = model.predict(input_data)\n#         print(prediction)\n#         return prediction\n#     else:\n#         return input_data\n        \n    \nif __name__ == \"__main__\":\n\n    print(\"[INFO] Extracting arguments\")\n    parser = argparse.ArgumentParser()\n\n    # hyperparameters sent by the client are passed as command-line arguments to the script.\n    parser.add_argument(\"--n_estimators\", type=int, default=100)\n    parser.add_argument(\"--random_state\", type=int, default=0)\n\n    # Data, model, and output directories\n    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n    parser.add_argument(\"--train-file\", type=str, default=\"train-V-1.csv\")\n    parser.add_argument(\"--test-file\", type=str, default=\"test-V-1.csv\")\n\n    args, _ = parser.parse_known_args()\n    \n    print(\"SKLearn Version: \", sklearn.__version__)\n    print(\"Joblib Version: \", joblib.__version__)\n\n    print(\"[INFO] Reading data\")\n    print()\n    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n    \n    features = list(train_df.columns)\n    label = features.pop(-1)\n    \n    print(\"Building training and testing datasets\")\n    print()\n    X_train = train_df[features]\n    X_test = test_df[features]\n    y_train = train_df[label]\n    y_test = test_df[label]\n\n    print('Column order: ')\n    print(features)\n    print()\n    \n    print(\"Label column is: \",label)\n    print()\n    \n    print(\"Data Shape: \")\n    print()\n    print(\"---- SHAPE OF TRAINING DATA (85%) ----\")\n    print(X_train.shape)\n    print(y_train.shape)\n    print()\n    print(\"---- SHAPE OF TESTING DATA (15%) ----\")\n    print(X_test.shape)\n    print(y_test.shape)\n    print()\n    \n  \n    print(\"Training RandomForest Model.....\")\n    print()\n    model =  RandomForestClassifier(n_estimators=args.n_estimators, random_state=args.random_state, verbose = 3,n_jobs=-1)\n    model.fit(X_train, y_train)\n    print()\n    \n\n    model_path = os.path.join(args.model_dir, \"model.joblib\")\n    joblib.dump(model,model_path)\n    print(\"Model persisted at \" + model_path)\n    print()\n\n    \n    y_pred_test = model.predict(X_test)\n    test_acc = accuracy_score(y_test,y_pred_test)\n    test_rep = classification_report(y_test,y_pred_test)\n\n    print()\n    print(\"---- METRICS RESULTS FOR TESTING DATA ----\")\n    print()\n    print(\"Total Rows are: \", X_test.shape[0])\n    print('[TESTING] Model Accuracy is: ', test_acc)\n    print('[TESTING] Testing Report: ')\n    print(test_rep)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! python script.py --n_estimators 100 \\\n                   --random_state 0 \\\n                   --model-dir ./ \\\n                   --train ./ \\\n                   --test ./ \\","metadata":{"scrolled":true,"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Train script in-side Sagemaker container.","metadata":{"tags":[]}},{"cell_type":"code","source":"from sagemaker.sklearn.estimator import SKLearn\n\nFRAMEWORK_VERSION = \"0.23-1\"\n\nsklearn_estimator = SKLearn(\n    entry_point=\"script.py\",\n    role=get_execution_role(),\n    instance_count=1,\n    instance_type=\"ml.m5.large\",\n    framework_version=FRAMEWORK_VERSION,\n    base_job_name=\"RF-custom-sklearn\",\n    hyperparameters={\n        \"n_estimators\": 100,\n        \"random_state\": 0,\n    },\n    use_spot_instances = True,\n    max_wait = 7200,\n    max_run = 3600\n)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# launch training job, with asynchronous call\nsklearn_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=True)\n# sklearn_estimator.fit({\"train\": datapath}, wait=True)","metadata":{"scrolled":true,"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. Store Model Artifacts(model.tar.gz) into the S3 Bucket. ","metadata":{"tags":[]}},{"cell_type":"code","source":"sklearn_estimator.latest_training_job.wait(logs=\"None\")\nartifact = sm_boto3.describe_training_job(\n    TrainingJobName=sklearn_estimator.latest_training_job.name\n)[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n\nprint(\"Model artifact persisted at \" + artifact)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9. Deploy Sagemaker Endpoint(API) for trained model, and test it. ","metadata":{"tags":[]}},{"cell_type":"code","source":"from sagemaker.sklearn.model import SKLearnModel\nfrom time import gmtime, strftime\n\nmodel_name = \"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\nmodel = SKLearnModel(\n    name =  model_name,\n    model_data=artifact,\n    role=get_execution_role(),\n    entry_point=\"script.py\",\n    framework_version=FRAMEWORK_VERSION,\n)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"endpoint_name = \"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\nprint(\"EndpointName={}\".format(endpoint_name))\n\npredictor = model.deploy(\n    initial_instance_count=1,\n    instance_type=\"ml.m4.xlarge\",\n    endpoint_name=endpoint_name,\n)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testX[features][0:2].values.tolist()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(predictor.predict(testX[features][0:2].values.tolist()))","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Don't forget to delete the endpoint !","metadata":{"tags":[]}},{"cell_type":"code","source":"sm_boto3.delete_endpoint(EndpointName=endpoint_name)","metadata":{"tags":[]},"execution_count":null,"outputs":[]}]}